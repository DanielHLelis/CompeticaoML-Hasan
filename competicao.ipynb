{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598758604491",
   "display_name": "Python 3.6.10 64-bit ('hasan': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Membros\n",
    "\n",
    "- Amanda Oliveira\n",
    "- Daniel Henrique\n",
    "- Samuel Pedro\n",
    "\n",
    "## Resumo\n",
    "\n",
    "### Parâmetros\n",
    "\n",
    "Será usado um kernel `rbf` em um kernel SVC. O `C` será otimizado pelo Optuna a fim de obter um resultado melhor. O `gamma` foi deixado no valor padrão que é `scale`, a fórmula referente a esse valor está disponível na documentação do scikit-learn.\n",
    "\n",
    "### Representação adotada\n",
    "\n",
    "A representação adotada foi escalar os valores númericos com um scaler do sklearn (no momento, um RobustScaler). Criar uma bag of words a partir do resumo. Criar uma bag of items com o elenco. Extrair o ano da data de estreia. E, por fim, descartar a história original e o titulo por não serem tão relevantes para os resultados. A coluna \"adulo\" foi deixada mesmo estando distribuida de maneira extremamente desuniforme, assumindo-se que o modelo irá incorporá-la melhor caso ela seja distribuída mais uniformemente.\n",
    "\n",
    "Porém, o resultado mais efeitvo usa apenas a bag of words e a bag of items, descartando os demais fatores. Isso provavelmente está relacionado com a grande ausência de informações (NaNs) dos demais parâmetros.\n",
    "\n",
    "### Método adotado\n",
    "\n",
    "O método adotado foi um classificador SVC com um kernel `rbf`, já que sua acurácia se mostrou maior que o `linear`. O kernel `poly` não foi testado por falta de tempo, mas espera-se que ele seja menos preciso em grais baixos ou consideravelmente mais lento em grais altos. \n",
    "\n",
    "Os resultados do método Random Forest são levemente inferiores, mas conseguem incorporar mais informações para a predição.\n",
    "\n",
    "## Pós-análise\n",
    "\n",
    "Após algumas reflexões, percebeu-se que o modelo era altamente dependente ao resumo, o que não é algo necessariamente ruim. Por conta disso, decidimos adotar uma representação que consiste basicamente do resumo com uma limpeza aplicada por cima. Para os filmes que não se têm um resumo, usaremos um segundo modelo baseado em RandomForest para prever a categoria baseando-se nos demais parâmetros, caso esse modelo mostre-se insuficientemente preciso, substituiremos-o por uma escolha fixa do gênero comédia, já que esse é o valor estatisticamente mais comum para esse caso de borda em específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from competicao_am.gerar_resultado_teste import gerar_saida_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       id                         titulo  adulto  orcamento idioma_original  \\\n0   86295  Treasure of the Yankee Zephyr   False          0              en   \n1  289198                       Redeemer   False          0              es   \n\n   popularidade data_de_estreia  \\\n0           2.0      1981-11-28   \n1           2.0      2014-09-18   \n\n                                              resumo  receita  duracao  \\\n0  In a lake high in the mountains of New Zealand...      0.0    108.0   \n1  A former hit-man for a drug cartel becomes a v...      0.0     88.0   \n\n   genero       ator_1             ator_2             ator_3           ator_4  \\\n0  Action     Ken Wahl  Lesley Ann Warren   Donald Pleasence   George Peppard   \n1  Action  Marko Zaror     Loreto Aravena  Mauricio Diocares  José Luís Mósca   \n\n           ator_5           dirigido_por     escrito_por_1 escrito_por_2  \\\n0  Bruno Lawrence         David Hemmings  Everett De Roche           NaN   \n1      Noah Segan  Ernesto Díaz Espinoza               NaN           NaN   \n\n  historia_original  \n0               NaN  \n1               NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>titulo</th>\n      <th>adulto</th>\n      <th>orcamento</th>\n      <th>idioma_original</th>\n      <th>popularidade</th>\n      <th>data_de_estreia</th>\n      <th>resumo</th>\n      <th>receita</th>\n      <th>duracao</th>\n      <th>genero</th>\n      <th>ator_1</th>\n      <th>ator_2</th>\n      <th>ator_3</th>\n      <th>ator_4</th>\n      <th>ator_5</th>\n      <th>dirigido_por</th>\n      <th>escrito_por_1</th>\n      <th>escrito_por_2</th>\n      <th>historia_original</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>86295</td>\n      <td>Treasure of the Yankee Zephyr</td>\n      <td>False</td>\n      <td>0</td>\n      <td>en</td>\n      <td>2.0</td>\n      <td>1981-11-28</td>\n      <td>In a lake high in the mountains of New Zealand...</td>\n      <td>0.0</td>\n      <td>108.0</td>\n      <td>Action</td>\n      <td>Ken Wahl</td>\n      <td>Lesley Ann Warren</td>\n      <td>Donald Pleasence</td>\n      <td>George Peppard</td>\n      <td>Bruno Lawrence</td>\n      <td>David Hemmings</td>\n      <td>Everett De Roche</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>289198</td>\n      <td>Redeemer</td>\n      <td>False</td>\n      <td>0</td>\n      <td>es</td>\n      <td>2.0</td>\n      <td>2014-09-18</td>\n      <td>A former hit-man for a drug cartel becomes a v...</td>\n      <td>0.0</td>\n      <td>88.0</td>\n      <td>Action</td>\n      <td>Marko Zaror</td>\n      <td>Loreto Aravena</td>\n      <td>Mauricio Diocares</td>\n      <td>José Luís Mósca</td>\n      <td>Noah Segan</td>\n      <td>Ernesto Díaz Espinoza</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "df_treino = pd.read_csv('datasets/movies_amostra.csv')\n",
    "df_predict = pd.read_csv('datasets/movies_amostra_teste_ex.csv')\n",
    "\n",
    "df_treino.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from competicao_am.preprocessamento_atributos_competicao import DataframePreprocessing\n",
    "preprocessor = DataframePreprocessing(df_treino, df_treino, 'genero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimização dos parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pickle # Serialização dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "\n",
    "from base_am.resultado import Fold\n",
    "from base_am.avaliacao import Experimento\n",
    "import competicao_am.metodo_competicao as mc\n",
    "import competicao_am.avaliacao_competicao as ac\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Um pouco sobre SVC's\n",
    "\n",
    "### Kernel\n",
    "\n",
    "O `kernel` indica o tipo de \"hiper-plano\" usado para separar as classes.\n",
    "\n",
    "Os kernels a serem considerados são: `linear`, `rbf` e `poly`\n",
    "\n",
    "#### `poly`: degree\n",
    "\n",
    "Grau do polinômio a ser usado. Quanto maior o valor, maior o tempo gasto para o treino.\n",
    "\n",
    "### gamma\n",
    "\n",
    "Parâmetro usado para \"hiper-planos\" não lineares. Quanto maior, mais ele tenta en encaixar o modelo perfeitamente.\n",
    "\n",
    "Valores muito altos caminhão em direção de um _overfitting_.\n",
    "\n",
    "### C\n",
    "\n",
    "C é o parâmetro de penalidade do erro. Ele controla o prejuízo entre paredes de decisões suaves e classificar os pontos corretamente.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links úteis:\n",
    "\n",
    "- [A guide to SVM parameter tuning](https://towardsdatascience.com/a-guide-to-svm-parameter-tuning-8bfe6b8a452c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experimento(metodo: mc.MetodoCompeticaoValidacaoSVM, num_trials: int = 2, otimizador:ac.OtimizacaoObjetivo = ac.OtimizacaoObjetivoSVCRbfComGamma, ml_method = None) -> Experimento:\n",
    "    folds = Fold.gerar_k_folds(df_treino, val_k=5, col_classe=\"genero\",\n",
    "                                num_repeticoes=1, num_folds_validacao=4, num_repeticoes_validacao=1)\n",
    "\n",
    "    ClasseObjetivo = ac.WrapperOtimizacaoObjetivo(otimizador, metodo=metodo)\n",
    "\n",
    "    experimento = Experimento(folds, ml_method=ml_method, ClasseObjetivoOtimizacao=ClasseObjetivo, num_trials=num_trials)\n",
    "\n",
    "    return experimento\n",
    "\n",
    "def best_parameters(experiment: Experimento):\n",
    "    results = []\n",
    "    for study in experiment.studies_per_fold:\n",
    "        results.append((study.best_trial.value, study.best_trial.params))\n",
    "    results.sort()\n",
    "    return list(reversed(sorted(results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "g_version = 2\n",
    "\n",
    "def do_experiment(name: str, metodo: mc.MetodoCompeticaoValidacaoSVM = None, num_trials: int = None, otimizador:ac.OtimizacaoObjetivo = None, ml_method = None, force: bool = False, version: int = g_version) -> Experimento:\n",
    "    file_name = f'{name}__{version}.p'\n",
    "    file_path = f'resultados/{file_name}'\n",
    "\n",
    "    if not force and os.path.isfile(file_path):\n",
    "        exp = None\n",
    "\n",
    "        with open(file_path, 'rb') as exp_p:\n",
    "            exp = pickle.load(exp_p)\n",
    "            # Check instance here\n",
    "\n",
    "        return exp\n",
    "    \n",
    "    if ml_method is None and (metodo is None or num_trials is None or otimizador is None):\n",
    "        raise ValueError('To run the experiment, the appropriate parameters should be give (ml_method or metodo, num_trials and otimizador)')\n",
    "\n",
    "    exp = experimento(metodo=metodo, num_trials=num_trials, otimizador=otimizador, ml_method=ml_method)\n",
    "    macro_f1 = exp.macro_f1_avg\n",
    "\n",
    "    with open(file_path, 'wb') as exp_p:\n",
    "        # exp = pickle.dump(exp, exp_p)\n",
    "        pass\n",
    "\n",
    "    return exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_test_rf = do_experiment('exp_test_rf', mc.MetodoCompeticaoValidacaoRF, 1000, ac.OtimizacaoObjetivoRandomForest, version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_test_svm = do_experiment('exp_test_svm', mc.MetodoCompeticaoValidacaoSVM, 100, ac.OtimizacaoObjetivoSVCRbfComGamma, version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[\n    [\n        0.596445251683727,\n        {\n            \"min_samples_split\": 0.04466339369901853,\n            \"max_features\": 0.0010292429905777445,\n            \"num_arvores\": 1\n        }\n    ],\n    [\n        0.5954073820857066,\n        {\n            \"min_samples_split\": 0.08842136011502941,\n            \"max_features\": 0.22848035048457271,\n            \"num_arvores\": 1\n        }\n    ],\n    [\n        0.5923505029598322,\n        {\n            \"min_samples_split\": 0.10251976896112781,\n            \"max_features\": 0.4785340513058907,\n            \"num_arvores\": 1\n        }\n    ],\n    [\n        0.5886801037590487,\n        {\n            \"min_samples_split\": 0.12650146532653397,\n            \"max_features\": 0.32474851683945516,\n            \"num_arvores\": 2\n        }\n    ],\n    [\n        0.5874204938135473,\n        {\n            \"min_samples_split\": 0.1164735770300016,\n            \"max_features\": 0.45935262471729577,\n            \"num_arvores\": 1\n        }\n    ]\n]\n[\n    [\n        0.7841233502726488,\n        {\n            \"exp_cost\": 1.8103213437733223,\n            \"gamma\": 0.29314287596361527\n        }\n    ],\n    [\n        0.7742250017799,\n        {\n            \"exp_cost\": 2.9461571639714297,\n            \"gamma\": 0.5065359268442085\n        }\n    ],\n    [\n        0.7711081220319707,\n        {\n            \"exp_cost\": 1.5848032924797064,\n            \"gamma\": 0.3393177716513029\n        }\n    ],\n    [\n        0.7672800702317709,\n        {\n            \"exp_cost\": 2.364547751708324,\n            \"gamma\": 0.19360170316818714\n        }\n    ],\n    [\n        0.7626444077251564,\n        {\n            \"exp_cost\": 2.066480881011902,\n            \"gamma\": 0.41917634410149274\n        }\n    ]\n]\n"
    }
   ],
   "source": [
    "print(json.dumps(best_parameters(exp_test_rf), indent=4))\n",
    "print(json.dumps(best_parameters(exp_test_svm), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}